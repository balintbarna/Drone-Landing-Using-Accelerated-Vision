{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import the Notebook loader code, which enables the import of notebooks as if they were python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daipy.nb_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import numpy and matplotlib, because we will most certainly use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the Camera class from its notebook, which simplifies getting images from the USB Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daipy.cam import Camera\n",
    "cam = Camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should make sure that it's working... Let's capture a frame and display it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgb = cam.get_rgb()\n",
    "print(\"Camera image shape: \" + str(rgb.shape))\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the DPU module and use it to load the bitstream and the DNN model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")\n",
    "overlay.load_model(\"yolo/dk_yolov3_voc_416_416.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should take a look at the input and output tensors and make sure it lines up with what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "print(\"Input Tensors: \" + str(inputTensors))\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "print(\"Output Tensors: \" + str(outputTensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look at their shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inShapes = []\n",
    "for tensor in inputTensors:\n",
    "    inShapes.append(tuple(tensor.dims))\n",
    "print(\"Input Shapes: \" + str(inShapes))\n",
    "outShapes = []\n",
    "for tensor in outputTensors:\n",
    "    outShapes.append(tuple(tensor.dims))\n",
    "print(\"Output Shapes: \" + str(outShapes))\n",
    "\n",
    "im_res = (inShapes[0][1], inShapes[0][2])\n",
    "print(\"Required input image resolution: \" + str(im_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the input/output buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "for shape in outShapes:\n",
    "    output_data.append(np.empty(shape, dtype=np.float32, order=\"C\"))\n",
    "input_data = []\n",
    "for shape in inShapes:\n",
    "    input_data.append(np.empty(shape, dtype=np.float32, order=\"C\"))\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for easy inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daipy.preproc as pre\n",
    "import daipy.postproc as post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo.evaluator import Evaluator\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(img, display=False):\n",
    "    preprocessed = np.array(evaluator.pre_process(img, im_res), dtype=np.float32)\n",
    "    image[0,...] = preprocessed.reshape(image.shape[1:])\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    image_size = img.shape[:2]\n",
    "    boxes, scores, classes = evaluator.evaluate(output_data, image_size)\n",
    "    if display:\n",
    "        evaluator.draw_boxes(img, boxes, scores, classes)\n",
    "        px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
    "        _, ax = plt.subplots(1, figsize=(image_size[0]*px*2,image_size[1]*px*2))\n",
    "        _ = ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the inferencing for 10 camera frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    run(cam.get_rgb(), display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
